# Ollama Configuration
# The base URL where your Ollama server is running
OLLAMA_BASE_URL=http://localhost:11434/v1

# The Ollama model to use for processing chrome tab content
# Examples: llama2, qwen, mistral, etc.
OLLAMA_MODEL=llama2

# Optional: Authentication token for the native messaging bridge
# Only needed if the native host is started with --require-auth
# BRIDGE_AUTH_TOKEN=your-secret-token-here

# Optional: Exclude URLs from logs (comma-separated patterns)
# Useful to reduce noise from test URLs in logs
# Example: CHROME_TAB_LOG_EXCLUDE_URLS=example.com,test.local,localhost:3000
# CHROME_TAB_LOG_EXCLUDE_URLS=
